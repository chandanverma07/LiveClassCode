{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac7824df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "909fcfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\mail2\\OneDrive\\Desktop\\Ml_Data\\NLP_DATA\\twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dd0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"target\"] = data[\"class\"].map({0: \"Hate Speech\", 1: \"Hate Speech\", 2: \"No Hate and Offensive\"})\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f436b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc42f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hate_speech=data[[\"tweet\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bf6e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_hate_speech.head(1)\n",
    "#sb.countplot(x=\"class\",data=data)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46116bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sb.countplot(x=\"target\",data=data_hate_speech)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2993a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_hate_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc78ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4276e895",
   "metadata": {},
   "source": [
    "### raw tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b249c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "twwet_raw=np.array(data_hate_speech[\"tweet\"])\n",
    "twwet_raw_token=word_tokenize(twwet_raw[0])\n",
    "twwet_raw_token_freq=FreqDist(twwet_raw_token)\n",
    "#twwet_raw_token_freq.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1bf867",
   "metadata": {},
   "source": [
    "## Text Cleanup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d476ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "stop_words_list=stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cbae2057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0d07e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stop_words_list]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b13c4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>No Hate and Offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet                 target\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  No Hate and Offensive"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hate_speech.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07aeeab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hate_speech[\"clean_tweet\"]=data_hate_speech[\"tweet\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bdcb01c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>No Hate and Offensive</td>\n",
       "      <td>rt mayasolov woman shouldnt complain clean ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet                 target  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  No Hate and Offensive   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0   rt mayasolov woman shouldnt complain clean ho...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hate_speech.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c333c87",
   "metadata": {},
   "source": [
    "### tfidf vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fbd47c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21effa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tweet=np.array(data_hate_speech[\"clean_tweet\"])\n",
    "y_target=np.array(data_hate_speech[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dbbe6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(np.unique(x_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ae8f31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vector=TfidfVectorizer(use_idf=True,ngram_range=(2,2))\n",
    "xvector=tf_idf_vector.fit_transform(x_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "73cf11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_idf_vector.get_feature_names_out()\n",
    "#tf_idf_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "60c130c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 124694)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bfc00b",
   "metadata": {},
   "source": [
    "### splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "824c4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d333c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(xvector,y_target,test_size=.30,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "53903678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3777735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_trainer=LogisticRegression()\n",
    "lr_learner=lr_trainer.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8b076",
   "metadata": {},
   "source": [
    "### testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "94923961",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=[\"i spend my money how i want bitch its my business \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f1f70181",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input=tf_idf_vector.transform(input_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "010c0890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90575048, 0.09424952]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_learner.predict(model_input)\n",
    "lr_learner.predict_proba(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1d38dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6711180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "YA=ytest\n",
    "YP=lr_learner.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7b1ba877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3cc73806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.68527236045729"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(YA,YP)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7194a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
